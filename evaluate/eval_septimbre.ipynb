{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"音色分离转录\"模型评估\n",
    "\n",
    "## 生成转录结果并保存\n",
    "经过process后每个文件夹里的文件只有后缀不同，且后缀为\"npy\" \"wav\" \"mid\"。wav采样率已经是22050Hz。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "s_per_frame = 256 / 22050\n",
    "\n",
    "# 由于BACH每个曲子都是四个固定的音色，且四种音色差异较大，因此只评估这一个数据集\n",
    "dataset_folders = [\"BACH10_processed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取转录结果，结果如下：\n",
    "```\n",
    "folder_2&3&4    // 数字个数和mix有关\n",
    "    | emb.npy   // [D, F, T]\n",
    "    | note.npy  // [F, T]\n",
    "    | midi.npy  // [mix, F, T]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def amt_mix(model, folders, normalize=True):\n",
    "    \"\"\"\n",
    "    mix audios and get AMT results\n",
    "    folders: [\"music@1\", \"music@2\", ...], each folder contains .npy and .wav\n",
    "    \"\"\"\n",
    "    # get all the wav & midi\n",
    "    waveforms = []\n",
    "    midis = []\n",
    "    for folder in folders:\n",
    "        filename = os.listdir(folder)[0]\n",
    "        path = os.path.join(folder, filename)[:-3]    # 去掉后缀\n",
    "        _wave, sr = torchaudio.load(path+'wav') # wave: [1, T], sr = 22050\n",
    "        waveforms.append(_wave)\n",
    "        midi = np.load(path+\"npy\")\n",
    "        midis.append(midi)\n",
    "    # mix wav\n",
    "    max_length = max(wave.shape[1] for wave in waveforms)\n",
    "    mix_wave = torch.zeros(1, max_length)\n",
    "    for wave in waveforms:\n",
    "        mix_wave[:, :wave.shape[1]] += wave\n",
    "    mix_wave.unsqueeze_(0)  # [1, 1, T]\n",
    "    # model output\n",
    "    emb, note, onset = model(mix_wave)\n",
    "    emb = emb.cpu().numpy()[0]  # [D, F, T]\n",
    "    note = note.cpu().numpy()[0]  # [F, T]\n",
    "    if normalize:\n",
    "        note = note / np.max(note)  # [F, T]\n",
    "    # padding midi in time axis\n",
    "    freqs, times = note.shape\n",
    "    for i in range(len(midis)):\n",
    "        midi = midis[i]\n",
    "        if midi.shape[1] < times:\n",
    "            padding = np.zeros((freqs, times - midi.shape[1]))\n",
    "            midis[i] = np.concatenate((midi, padding), axis=1)\n",
    "        elif midi.shape[1] > times:\n",
    "            midis[i] = midi[:, :times]\n",
    "    midis = np.stack(midis, axis=0)  # [len(folders), F, T]\n",
    "    return emb, note, midis\n",
    "\n",
    "def amt_mix_dataset(model, dataset_folder, mix, output_folder):\n",
    "    \"\"\"\n",
    "    mix audios in dataset and get AMT results\n",
    "    dataset_folder: \"BACH10_processed\", in which each ensemble contains 4 instruments\n",
    "    \"\"\"\n",
    "    folder_name = os.path.basename(dataset_folder)\n",
    "    output_folder_name = folder_name.split(\"_\")[0] + \"_eval\"\n",
    "    output_path = os.path.join(output_folder, output_folder_name)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    folders = os.listdir(dataset_folder)\n",
    "    for folder in folders:\n",
    "        # find folders that end with 0\n",
    "        # e.g. \"music@0\"\n",
    "        if not os.path.isdir(os.path.join(dataset_folder, folder)):\n",
    "            continue\n",
    "        if not folder.endswith(\"0\"):\n",
    "            continue\n",
    "        piece_name = folder[:-2]\n",
    "        # find all folders that start with the same piece name\n",
    "        # e.g. \"music@1\", \"music@2\", \"music@3\", \"music@4\"\n",
    "        parts = []\n",
    "        for f in folders:\n",
    "            path = os.path.join(dataset_folder, f)\n",
    "            if not os.path.isdir(path):\n",
    "                continue\n",
    "            if f.startswith(piece_name) and (not f.endswith(\"0\")):\n",
    "                parts.append(path)\n",
    "        # choose {mix} folders to mix\n",
    "        if len(parts) < mix:\n",
    "            print(f\"Not enough parts for {piece_name}, skip\")\n",
    "            continue\n",
    "        for selected_parts in combinations(parts, mix):\n",
    "            processing_piece_name = piece_name + \"_\" + '&'.join([part[-1] for part in selected_parts])\n",
    "            print(f\"Processing {processing_piece_name}\")\n",
    "            emb, note, midis = amt_mix(model, selected_parts)\n",
    "            # save emb, note, midis\n",
    "            folder_path = os.path.join(output_path, processing_piece_name)\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            # save emb\n",
    "            np.save(os.path.join(folder_path, \"emb.npy\"), emb)\n",
    "            np.save(os.path.join(folder_path, \"note.npy\"), note)\n",
    "            np.save(os.path.join(folder_path, \"midi.npy\"), midis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算帧级的评价指标\n",
    "from utils.midiarray import freq_map, roll2evalarray\n",
    "from utils.postprocess import min_len_\n",
    "import mir_eval\n",
    "\n",
    "s_per_frame = 256 / 22050\n",
    "freqmap = freq_map((24, 107), 440)\n",
    "\n",
    "def frame_eval(note, midi, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    对note进行阈值二值化、移除短音符、转换为mir_eval所需数\n",
    "    计算帧级评价指标\n",
    "    note: (freqs, times)\n",
    "    midi: (freqs, times)\n",
    "    \"\"\"\n",
    "    binary_note = (note > threshold).astype(int)    # 二值化\n",
    "    # 这个min_len_是原位操作，会修改输入\n",
    "    est_pitch = roll2evalarray(min_len_(binary_note, 3), freqmap)\n",
    "    ref_pitch = roll2evalarray(midi, freqmap)\n",
    "    rst_time = s_per_frame * np.arange(len(est_pitch))\n",
    "    ref_time = s_per_frame * np.arange(len(ref_pitch))\n",
    "    result = mir_eval.multipitch.evaluate(ref_time, ref_pitch, rst_time, est_pitch)\n",
    "    return result   # https://github.com/mir-evaluation/mir_eval/blob/main/mir_eval/multipitch.py\n",
    "\n",
    "\n",
    "def evaluate_frame_dataset(npy_folders, threshold = 0.5, log = True):\n",
    "    \"\"\"\n",
    "    对npy_folders中的所有folder下的note.npy文件用同一个阈值进行评估，目标值是同一文件夹下的midi.npy在dim0求max\n",
    "    \"\"\"\n",
    "    accs = []\n",
    "    ps = []\n",
    "    rs = []\n",
    "    f1s = []\n",
    "    for npy_folder in npy_folders:\n",
    "        amt_result = np.load(os.path.join(npy_folder, \"note.npy\"))\n",
    "        ground_truth = np.load(os.path.join(npy_folder, \"midi.npy\"))    # [mix, F, T]\n",
    "        ground_truth = np.max(ground_truth, axis=0, keepdims=False)\n",
    "        evaluation = frame_eval(amt_result, ground_truth, threshold)\n",
    "        acc = evaluation['Accuracy']\n",
    "        p = evaluation['Precision']\n",
    "        r = evaluation['Recall']\n",
    "        accs.append(acc)\n",
    "        ps.append(p)\n",
    "        rs.append(r)\n",
    "        f1s.append(2*p*r/(p+r) if p+r > 0 else 0)\n",
    "    ACC = np.mean(accs)\n",
    "    P = np.mean(ps)\n",
    "    R = np.mean(rs)\n",
    "    F1 = np.mean(f1s)\n",
    "    if log:\n",
    "        # | Acc | P | R | F1 |\n",
    "        print(f\"| {threshold:.5f} | {ACC:.5f} | {P:.5f} | {R:.5f} | {F1:.5f} |\")\n",
    "    return ACC, P, R, F1\n",
    "\n",
    "\n",
    "def find_best_threshold(npy_pathes, origin_range = (0.1, 0.9), step_num = 10, generation = 4, log = True):\n",
    "    if log:\n",
    "        print(\"| threshold | Acc | P | R | F1 |\")\n",
    "        print(\"| --------- | --- |---|---|----|\")\n",
    "    \n",
    "    start = origin_range[0]\n",
    "    end = origin_range[1]\n",
    "    step = (end - start) / step_num\n",
    "    \n",
    "    best_thre = -1\n",
    "    max_f1 = -1\n",
    "    best_thre_idx = -1\n",
    "\n",
    "    for g in range(generation):\n",
    "        lastF1 = -1\n",
    "        thresholds = np.r_[start:end:step]\n",
    "        for idx, thre in enumerate(thresholds):\n",
    "            ACC, P, R, F1 = evaluate_frame_dataset(npy_pathes, thre, log)\n",
    "            if F1 > max_f1:\n",
    "                max_f1 = F1\n",
    "                best_thre_idx = idx\n",
    "                best_thre = thre\n",
    "            if F1 < lastF1: # 假设F1是一个凹函数，只要开始下降就可以停止了\n",
    "                break\n",
    "            lastF1 = F1\n",
    "        if log:\n",
    "            print(f\"| Best threshold | {best_thre} | ~ | ~ | F1: {max_f1} |\")\n",
    "        \n",
    "        # 如果是边缘的话，下一轮start不会覆盖到最优值，所以提前加入；否则清空\n",
    "        if best_thre_idx == -1: # 说明最优值还在左边\n",
    "            best_thre_idx = -1  # -1表示最大值在左边外面\n",
    "            start = best_thre\n",
    "            end = thresholds[0]\n",
    "            step = (end - start) / step_num\n",
    "            start += step\n",
    "        elif best_thre_idx == 0:    # 最值就是最左边的\n",
    "            best_thre_idx = -1\n",
    "            start = best_thre\n",
    "            end = thresholds[1]\n",
    "            step = (end - start) / step_num\n",
    "            start += step\n",
    "        elif best_thre_idx == -2:   # 如果是右边缘的右边最大，说明最优值还在右边\n",
    "            best_thre_idx = -2      # -2表示最大值在右边外面\n",
    "            start = thresholds[-1]\n",
    "            end = best_thre\n",
    "            step = (end - start) / step_num\n",
    "            start += step\n",
    "        elif best_thre_idx == len(thresholds) - 1:  # 最值就是最右边的\n",
    "            best_thre_idx = -2\n",
    "            start = thresholds[-2]\n",
    "            end = best_thre\n",
    "            step = (end - start) / step_num\n",
    "            start += step\n",
    "        else:\n",
    "            start = thresholds[best_thre_idx-1]\n",
    "            end = thresholds[best_thre_idx+1]\n",
    "            step = (end - start) / step_num\n",
    "            start += step   # 少分析一轮\n",
    "            max_f1 = -1     # 清空最大值，因为一定在区间内\n",
    "\n",
    "    return best_thre\n",
    "\n",
    "\n",
    "def ifNmix(f, mix):\n",
    "    \"\"\"\n",
    "    judge whether f is mixed with {mix} instruments\n",
    "    \"\"\"\n",
    "    mix_info = f.split(\"_\")[-1]\n",
    "    mix_num = mix_info.split(\"&\")\n",
    "    return len(mix_num) == mix\n",
    "\n",
    "\n",
    "from itertools import permutations\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def eval_sep(npyfolder, thres=0.262, mix = 2):\n",
    "    \"\"\"\n",
    "    在给定阈值的时候，评估分离效果\n",
    "    \"\"\"\n",
    "    accs = []\n",
    "    ps = []\n",
    "    rs = []\n",
    "    f1s = []\n",
    "    for f in os.listdir(npyfolder):\n",
    "        if not ifNmix(f, mix):\n",
    "            continue\n",
    "        npy_path = os.path.join(npyfolder, f)\n",
    "        emb = np.load(os.path.join(npy_path, \"emb.npy\"))\n",
    "        note = np.load(os.path.join(npy_path, \"note.npy\"))\n",
    "        midi = np.load(os.path.join(npy_path, \"midi.npy\"))\n",
    "        positions = np.where(note > thres)\n",
    "        emb_extracted = emb[:, positions[0], positions[1]].T        # (n, 18)\n",
    "        # 计算余弦相似度矩阵\n",
    "        similarity_matrix = cosine_similarity(emb_extracted)\n",
    "        # 进行谱聚类\n",
    "        spectral = SpectralClustering(n_clusters=mix, affinity='precomputed', assign_labels=\"cluster_qr\")\n",
    "        labels = spectral.fit_predict(np.exp(similarity_matrix))\n",
    "        # 将标签转换为二值化的音符矩阵\n",
    "        clustered_classes = []\n",
    "        for i in range(mix):\n",
    "            class_i = np.zeros(note.shape)\n",
    "            class_i[positions[0], positions[1]] = (labels == i).astype(float)\n",
    "            clustered_classes.append(class_i)\n",
    "        # 用PIT找到最优的对应顺序\n",
    "        lossmin = float(\"inf\")\n",
    "        lossset = None\n",
    "        for set in permutations(clustered_classes):\n",
    "            loss = np.sum(np.power(midi - np.stack(set, axis=0), 2))\n",
    "            if loss < lossmin:\n",
    "                lossmin = loss\n",
    "                lossset = set\n",
    "        # 计算帧级指标\n",
    "        for i in range(mix):\n",
    "            evaluation = frame_eval(lossset[i], midi[i], thres)\n",
    "            acc = evaluation['Accuracy']\n",
    "            p = evaluation['Precision']\n",
    "            r = evaluation['Recall']\n",
    "            accs.append(acc)\n",
    "            ps.append(p)\n",
    "            rs.append(r)\n",
    "            f1s.append(2*p*r/(p+r) if p+r > 0 else 0)\n",
    "    ACC = np.mean(accs)\n",
    "    P = np.mean(ps)\n",
    "    R = np.mean(rs)\n",
    "    F1 = np.mean(f1s)\n",
    "    return ACC, P, R, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"septimbre\"\n",
    "sys.path.append(f'../{model_folder_name}')\n",
    "model = torch.load(f\"../{model_folder_name}/cluster_model_0.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到所有2混合的运行结果\n",
    "with torch.no_grad():\n",
    "    for dataset_folder in dataset_folders:\n",
    "        amt_mix_dataset(model, dataset_folder, 2, f\"./{model_folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到所有3混合的运行结果\n",
    "with torch.no_grad():\n",
    "    for dataset_folder in dataset_folders:\n",
    "        amt_mix_dataset(model, dataset_folder, 3, f\"./{model_folder_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算帧级指标，并寻找最好阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACH10的2合奏\n",
    "npyfolder = f\"{model_folder_name}/BACH10_eval\"\n",
    "npys = [os.path.join(npyfolder, f) for f in os.listdir(npyfolder) if ifNmix(f, 2)]\n",
    "find_best_threshold(npys, (0.15, 0.5), step_num=10, generation=4, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BACH10的2合奏\n",
    "\n",
    "| threshold | Acc | P | R | F1 |\n",
    "| --------- | --- |---|---|----|\n",
    "| 0.15000 | 0.64117 | 0.71717 | 0.85224 | 0.77753 |\n",
    "| 0.18500 | 0.66473 | 0.76228 | 0.83237 | 0.79453 |\n",
    "| 0.22000 | 0.67532 | 0.79403 | 0.81222 | 0.80163 |\n",
    "| 0.25500 | 0.67929 | 0.81844 | 0.79298 | 0.80390 |\n",
    "| 0.29000 | 0.67868 | 0.83777 | 0.77436 | 0.80285 |\n",
    "| Best threshold | 0.255 | ~ | ~ | F1: 0.8039013756015501 |\n",
    "| 0.22700 | 0.67664 | 0.79943 | 0.80841 | 0.80247 |\n",
    "| 0.23400 | 0.67782 | 0.80446 | 0.80482 | 0.80320 |\n",
    "| 0.24100 | 0.67837 | 0.80930 | 0.80063 | 0.80344 |\n",
    "| 0.24800 | 0.67900 | 0.81401 | 0.79685 | 0.80378 |\n",
    "| 0.25500 | 0.67929 | 0.81844 | 0.79298 | 0.80390 |\n",
    "| 0.26200 | 0.67969 | 0.82285 | 0.78929 | 0.80404 |\n",
    "| 0.26900 | 0.67948 | 0.82671 | 0.78539 | 0.80378 |\n",
    "| Best threshold | **0.262** | ~ | ~ | F1: 0.8040439516526102 |\n",
    "| 0.25640 | 0.67929 | 0.81919 | 0.79226 | 0.80388 |\n",
    "| 0.25780 | 0.67929 | 0.81996 | 0.79150 | 0.80385 |\n",
    "| Best threshold | 0.2564 | ~ | ~ | F1: 0.8038820389334114 |\n",
    "| 0.25654 | 0.67932 | 0.81929 | 0.79221 | 0.80390 |\n",
    "| 0.25668 | 0.67934 | 0.81938 | 0.79215 | 0.80392 |\n",
    "| 0.25682 | 0.67930 | 0.81944 | 0.79204 | 0.80388 |\n",
    "| Best threshold | 0.25668 | ~ | ~ | F1: 0.8039166534485358 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACH10的3合奏\n",
    "npyfolder = f\"{model_folder_name}/BACH10_eval\"\n",
    "npys = [os.path.join(npyfolder, f) for f in os.listdir(npyfolder) if ifNmix(f, 3)]\n",
    "find_best_threshold(npys, (0.17, 0.5), step_num=10, generation=4, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BACH10的3合奏\n",
    "\n",
    "| threshold | Acc | P | R | F1 |\n",
    "| --------- | --- |---|---|----|\n",
    "| 0.17000 | 0.62409 | 0.78100 | 0.75324 | 0.76585 |\n",
    "| 0.20300 | 0.62266 | 0.81428 | 0.72261 | 0.76418 |\n",
    "| Best threshold | 0.17 | ~ | ~ | F1: 0.7658493742704697 |\n",
    "| 0.17330 | 0.62455 | 0.78481 | 0.75036 | 0.76614 |\n",
    "| 0.17660 | 0.62457 | 0.78834 | 0.74717 | 0.76611 |\n",
    "| Best threshold | 0.1733 | ~ | ~ | F1: 0.7661354741856663 |\n",
    "| 0.17363 | 0.62455 | 0.78516 | 0.75004 | 0.76614 |\n",
    "| 0.17396 | 0.62459 | 0.78556 | 0.74971 | 0.76616 |\n",
    "| 0.17429 | 0.62461 | 0.78593 | 0.74942 | 0.76617 |\n",
    "| 0.17462 | 0.62462 | 0.78631 | 0.74909 | 0.76618 |\n",
    "| 0.17495 | 0.62456 | 0.78664 | 0.74869 | 0.76612 |\n",
    "| Best threshold | 0.17462 | ~ | ~ | F1: 0.7661792926364324 |\n",
    "| 0.17436 | 0.62465 | 0.78602 | 0.74939 | 0.76620 |\n",
    "| 0.17442 | 0.62464 | 0.78609 | 0.74933 | 0.76620 |\n",
    "| Best threshold | **0.174356** | ~ | ~ | F1: 0.7661996540333392 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估分离效果\n",
    "找到帧级最佳阈值后，在此阈值进行分离转录的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC, P, R, F1 = eval_sep(npyfolder, thres=0.262, mix=2)\n",
    "print(\"| ACC | P | R | F1 |\")\n",
    "print(\"| --- | - | - | -- |\")\n",
    "print(f\"| {ACC} | {P} | {R} | {F1} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 二分离阈值0.262\n",
    "\n",
    "| ACC | P | R | F1 |\n",
    "| --- | - | - | -- |\n",
    "| 0.419190808246382 | 0.5864362845981422 | 0.557724271752085 | 0.562696806151991 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC, P, R, F1 = eval_sep(npyfolder, thres=0.174356, mix=3)\n",
    "print(\"| ACC | P | R | F1 |\")\n",
    "print(\"| --- | - | - | -- |\")\n",
    "print(f\"| {ACC} | {P} | {R} | {F1} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 三分离阈值0.174356\n",
    "\n",
    "| ACC | P | R | F1 |\n",
    "| --- | - | - | -- |\n",
    "| 0.2703082899407062 | 0.43615389833377094 | 0.4015866041003891 | 0.4071539736610125 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19944\n",
      "117700\n"
     ]
    }
   ],
   "source": [
    "# 输出参数数量\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model.cqt))\n",
    "print(count_parameters(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

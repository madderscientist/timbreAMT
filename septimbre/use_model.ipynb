{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../model\")\n",
    "model = torch.load(\"cluster_model_1.pth\", map_location=torch.device('cpu'))\n",
    "s_per_frame = 256 / 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from utils.midiarray import midi2numpy\n",
    "\n",
    "def draw_midi_with_channel(ax, midiarr, colors=['Reds', 'Blues'], labels=['Piano', 'Violin']):\n",
    "    \"\"\"\n",
    "    用不同颜色绘制midiarray\n",
    "    ax: 通常是plt的subplot的一张图\n",
    "    midiarr: 3D numpy array, shape = (n_channel, n_time, n_pitch) 或者midi路径\n",
    "    colors: 颜色列表，名字需要和plt.cm中的颜色一致\n",
    "    \"\"\"\n",
    "\n",
    "    # 从文件打开midi\n",
    "    if isinstance(midiarr, str):\n",
    "        midiarr = midi2numpy(midiarr, s_per_frame, track_separate=True)\n",
    "        if len(midiarr.shape) != 3:\n",
    "            raise ValueError(\"midiarr must be a 3D numpy array\")\n",
    "\n",
    "    Colors = [plt.get_cmap(color) if isinstance(color, str) else color for color in colors]\n",
    "    # 白色背景\n",
    "    background = np.ones_like(midiarr[0])\n",
    "    ax.imshow(background, cmap='gray_r', aspect='auto', origin='lower')\n",
    "\n",
    "    for i, ch in enumerate(midiarr):\n",
    "        # 预处理红色通道\n",
    "        red_data = np.zeros_like(ch, dtype=float)\n",
    "        alpha_red = np.zeros_like(ch, dtype=float)\n",
    "        # 设置不同透明度\n",
    "        red_data[ch > 0] = 1.0  # 红色值\n",
    "        alpha_red[ch == 1] = 0.6  # 半透明\n",
    "        alpha_red[ch == 2] = 1.0  # 不透明\n",
    "        # 绘制红色（使用 RGBA 数组）\n",
    "        red_rgba = Colors[i](red_data)  # 获取 RGBA 颜色\n",
    "        red_rgba[..., 3] = alpha_red  # 修改透明度通道\n",
    "        ax.imshow(red_rgba, aspect='auto', origin='lower')\n",
    "\n",
    "    if len(labels) != len(colors):\n",
    "        return\n",
    "    legend_elements = [Patch(facecolor=Colors[i](0.8), alpha=0.6, label=labels[i]) for i in range(len(labels))]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取音频\n",
    "import torchaudio\n",
    "from utils.wavtool import waveInfo\n",
    "from utils.midiarray import midi2numpy\n",
    "import os\n",
    "\n",
    "# test_wave_path = \"../data/inferMusic/short mix.wav\"\n",
    "test_wave_path = \"../data/inferMusic/three_mix.wav\"\n",
    "# test_wave_path = \"../data/inferMusic/孤独な巡礼simple.wav\"\n",
    "\n",
    "# 尝试获取midi\n",
    "test_midi = test_wave_path.replace(\".wav\", \".mid\")\n",
    "if os.path.exists(test_midi):\n",
    "    test_midi = midi2numpy(test_midi, s_per_frame, track_separate=True)\n",
    "else:\n",
    "    test_midi = None\n",
    "\n",
    "info = waveInfo(test_wave_path)\n",
    "\n",
    "waveform, sample_rate = torchaudio.load(test_wave_path, normalize=True)\n",
    "waveform = waveform.unsqueeze(0)\n",
    "if info[\"sample_rate\"] > 44000:\n",
    "    waveform = model.cqt.down2sample(waveform)\n",
    "    print(f\"$ downsampled to {info[\"sample_rate\"]//2}Hz\")\n",
    "print(waveform.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用聚类\n",
    "需要明确类别数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 3\n",
    "# 假设 model 和 test_cqt_data 已经定义\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    emb, mask, onset = model(waveform)\n",
    "    emb = emb / torch.sqrt(emb.pow(2).sum(dim=1, keepdim=True) + 1e-8)\n",
    "    emb = emb.cpu().numpy()[0]      # (18, 84, frame)\n",
    "    mask = mask.cpu().numpy()[0]    # (84, frame)\n",
    "    onset = onset.cpu().numpy()[0]\n",
    "\n",
    "if test_midi is not None:\n",
    "    emb = emb[:, :, :test_midi.shape[2]]  # 截取到和midi一样长\n",
    "    mask = mask[:, :test_midi.shape[2]]    # 截取到和midi一样长\n",
    "    onset = onset[:, :test_midi.shape[2]]  # 截取到和midi一样长\n",
    "\n",
    "# mask大于阈值的数目记为n\n",
    "positions = np.where(mask > 0.55)\n",
    "emb_extracted = emb[:, positions[0], positions[1]].T        # (n, 18)\n",
    "\n",
    "# 计算余弦相似度矩阵\n",
    "similarity_matrix = cosine_similarity(emb_extracted)\n",
    "\n",
    "# 进行谱聚类\n",
    "spectral = SpectralClustering(n_clusters=N, affinity='precomputed', assign_labels=\"cluster_qr\")\n",
    "labels = spectral.fit_predict(np.exp(similarity_matrix))\n",
    "\n",
    "pre_figures = 2 + (0 if test_midi is None else 1)\n",
    "sub_figures = N + pre_figures\n",
    "\n",
    "plt.figure(figsize=(10, 5*sub_figures))\n",
    "\n",
    "if test_midi is not None:\n",
    "    plt.subplot(sub_figures, 1, 1)\n",
    "    plt.title('midi')\n",
    "    draw_midi_with_channel(plt.gca(), test_midi, colors=['Reds', 'Blues', 'Greens'], labels=[])\n",
    "\n",
    "plt.subplot(sub_figures, 1, pre_figures - 1)\n",
    "plt.title('note')\n",
    "plt.imshow(mask, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(sub_figures, 1, pre_figures)\n",
    "plt.title('onset')\n",
    "plt.imshow(onset, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "clustered_classes = []\n",
    "for i in range(N):\n",
    "    class_i = np.zeros(mask.shape)\n",
    "    class_i[positions[0], positions[1]] = (labels == i).astype(int)\n",
    "    clustered_classes.append(class_i)\n",
    "    plt.subplot(sub_figures, 1, i + pre_figures + 1)\n",
    "    plt.title(f'class{i}')\n",
    "    plt.imshow(class_i, aspect='auto', origin='lower', cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取代聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到 mask 中最大值的位置\n",
    "max_position = np.unravel_index(np.argmax(mask, axis=None), mask.shape)\n",
    "# 提取对应的 emb 值\n",
    "max_emb = emb[:, max_position[0], max_position[1]]\n",
    "\n",
    "similarity_scores = np.tensordot(max_emb, emb*mask, axes=([0], [0])).reshape(emb.shape[1], emb.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('class_max')\n",
    "plt.imshow(similarity_scores, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(similarity_scores > 0.5, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = mask - similarity_scores\n",
    "s = similarity_scores#[similarity_scores < 0.01] = 0\n",
    "emb2 = emb - s * max_emb[:, None, None]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.title('mask-class_max')\n",
    "plt.imshow(mask2, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到 mask 中最大值的位置\n",
    "max_position2 = np.unravel_index(np.argmax(mask2, axis=None), mask.shape)\n",
    "# 提取对应的 emb 值\n",
    "max_emb2 = emb[:, max_position2[0], max_position2[1]]\n",
    "\n",
    "similarity_scores2 = np.tensordot(max_emb2, emb*mask, axes=([0], [0])).reshape(emb.shape[1], emb.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('class_max')\n",
    "plt.imshow(similarity_scores2, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(similarity_scores2 > 0.3, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

1:	train_loss: 498.1419	val_loss: 657.9304	467286.8356	249.2038	522849.5078	329.1723
2:	train_loss: 472.2831	val_loss: 675.2897	444317.5712	236.2671	515887.9809	337.8660
3:	train_loss: 459.0824	val_loss: 667.3040	430481.4536	229.6637	500666.7786	333.8745
4:	train_loss: 446.0023	val_loss: 633.4769	420928.5665	223.1193	498189.7934	316.9399
5:	train_loss: 436.9924	val_loss: 649.0913	413150.0139	218.6118	510201.3533	324.7522
6:	train_loss: 430.0229	val_loss: 694.9042	406229.5456	215.1253	500353.8646	347.6936
7:	train_loss: 422.8443	val_loss: 654.3672	400046.2053	211.5340	502089.2405	327.3970
8:	train_loss: 415.3197	val_loss: 654.3087	393319.9239	207.7696	498574.0139	327.3692
9:	train_loss: 409.7859	val_loss: 648.7003	387657.5990	205.0013	495842.8941	324.5624
10:	train_loss: 404.4022	val_loss: 646.7341	381741.9662	202.3083	494731.6319	323.5785
11:	train_loss: 401.8476	val_loss: 658.8290	376791.5594	201.0310	495422.7552	329.6337
12:	train_loss: 397.6560	val_loss: 667.0562	370251.6261	198.9348	488998.5087	333.7557
13:	train_loss: 395.0771	val_loss: 662.9080	365347.3866	197.6454	491076.9349	331.6778
14:	train_loss: 390.8662	val_loss: 657.3361	359533.5715	195.5394	502972.7318	328.8829
15:	train_loss: 387.8656	val_loss: 636.6174	354082.7133	194.0391	506583.2517	318.5088
16:	train_loss: 386.1273	val_loss: 647.6180	349507.7116	193.1704	498100.0321	324.0197
17:	train_loss: 384.0260	val_loss: 666.5309	345443.8955	192.1198	499206.7257	333.4881
18:	train_loss: 382.2788	val_loss: 630.3458	341016.4440	191.2466	501491.0720	315.3711
19:	train_loss: 380.8101	val_loss: 638.0941	338145.4069	190.5123	493541.5217	319.2534
20:	train_loss: 378.4819	val_loss: 676.9228	333361.0235	189.3485	490463.7765	338.6951
21:	train_loss: 376.0021	val_loss: 661.5309	330302.5293	188.1081	512198.2839	330.9792
22:	train_loss: 375.6394	val_loss: 624.8050	327192.2971	187.9276	503919.6233	312.5963
23:	train_loss: 374.2229	val_loss: 637.2021	324418.5430	187.2194	495050.0859	318.8062
24:	train_loss: 370.8063	val_loss: 647.7298	320788.2242	185.5104	500748.2457	324.0745
25:	train_loss: 369.4040	val_loss: 627.0004	318365.0834	184.8092	501619.7821	313.6962
26:	train_loss: 368.4722	val_loss: 653.5536	315418.3341	184.3438	500167.6354	326.9904
27:	train_loss: 368.3396	val_loss: 618.2324	313419.9585	184.2781	505114.7457	309.3055
28:	train_loss: 364.5181	val_loss: 619.1147	310300.3645	182.3661	488990.0703	309.7534
29:	train_loss: 363.0304	val_loss: 626.8768	308157.1562	181.6222	511709.9375	313.6305
30:	train_loss: 362.2524	val_loss: 610.9998	305762.9367	181.2336	505775.2135	305.6845
31:	train_loss: 361.6619	val_loss: 637.4078	304096.5551	180.9386	497928.0990	318.9080
32:	train_loss: 360.8357	val_loss: 629.7068	302255.0861	180.5256	495614.9418	315.0536
33:	train_loss: 358.2465	val_loss: 627.3292	299609.7513	179.2304	512451.4757	313.8567
34:	train_loss: 356.7721	val_loss: 623.9015	297717.5673	178.4930	508060.4358	312.1424
35:	train_loss: 355.5473	val_loss: 649.1371	295730.4810	177.8806	509368.1085	324.7755
36:	train_loss: 354.8723	val_loss: 624.8312	293546.7933	177.5435	506889.9245	312.6083
37:	train_loss: 353.5392	val_loss: 634.7233	291883.0107	176.8767	500945.1372	317.5628
38:	train_loss: 352.8611	val_loss: 670.4525	290442.3246	176.5378	514151.9314	335.4450
39:	train_loss: 350.7041	val_loss: 647.4405	288519.5288	175.4587	499496.3624	323.9302
40:	train_loss: 351.6788	val_loss: 636.6293	287596.7079	175.9470	508150.2005	318.5142
41:	train_loss: 350.5961	val_loss: 637.6480	285757.9312	175.4057	510582.4288	319.0232
